One of the objectives of this thesis is the implementation and analysis of a prototype App for mobile devices. In this chapter, the previously selected algorithms will be put into the context of the App's implementation, and the App's structure itself will be detailed. This chapter is structured as follows:

\begin{itemize}
	\item \textbf {About Android Apps} - An introduction to the Android operating system.
	\item \textbf {Assembly of Algorithms and Information Flow In Concrete Implementation} - Gives details on algorithms and information flow between them, as previously listed in an overview in Chapter ~\ref{ch:scenario}.
	\item \textbf {Illustrations of Algorithm Steps} - Lists illustrations and descriptions of the algorithm succession in the App prototype.
	\item \textbf {Retrieval of Music Metadata} - Describes how music metadata is retrieved from a mobile device's storage and from web sources.
	\item \textbf {Retrieval of Similarity Data} - Describes how artist similarity data is retrieved from web sources, and how unknown values are approximated.
	\item \textbf {Implementation of Multidimensional Scaling} - Contains a pseudo-code listing of one step in the MDS algorithm.
	\item \textbf {Implementation of Removal of Node Overlappings} - Contains a pseudo-code listing of the algorithm implementation which removes overlappings of graph nodes.
	\item \textbf {Visualization Details} - Features implementation details of the prototype concerning visualization of graph data.
	\item \textbf {Structure of the App} - Presents the structure of the prototypical App, together with information about the target operating system.
\end{itemize}

\section{Assembly of Algorithms and Information Flow In Concrete Implementation}
\label{sec:algorithm-assembly}

In Chapter ~\ref{ch:scenario}, an overview was given of how algorithms work together in the system. In-depth implementation-specific details of this assembly and information flow will now be given. These steps are in part also illustrated in Fig. ~\ref{fig:screen_mds_1_initial} to Fig. ~\ref{fig:screen_mds_10_after_all_uncollided_nodes}.

\subsection{About Android Apps}

Android is a mobile operating system developed by the Open Handset Alliance ~\cite{url:openhandsetalliance}, led by Google. Its architecture allows for 3rd party programs (called "'apps"') to easily be run and debugged on Android devices.
Android apps are run in the Dalvik VM \footnote{A Virtual Machine (VM) is the emulation of computing hardware on which software can be run which is tailored to the emulated architecture, without ever owning the actual hardware. Virtual Machines are usually executed as programs on a host operating system. Android's Dalvik VM allows to execute computer code without the need to compile it up front, like the Java VM, from which it is derived.} which makes use of a register-based architecture, relying on a Linux kernel for low-level functionality ~\cite{dalvik}. The most wide-spread programming language for building Android apps is Java, but various other languages such as Scala or even scripting languages like Groovy or Lua can be used. Since mid 2009, developers can also write and integrate native C and C++ code by making use of the Native Development Kit (NDK).

From an app developer's perspective, the frameworks contained in Android dictate a user-centric application structure, made up of so-called Activities ~\cite{url:androidactivity}. Every Activity encapsulates a screen which is presented to the user. Activities are loosely coupled, allowing only serialized objects and primitive values to be passed between them.

User interface composition in Android is performed partly in the CPU (e.g., in Java code), and partly in the device's GPU (by using the OpenGL interface). Apps can also choose between these composition variants.

Android is a strictly touch-centric operating system, meaning that most user interactions are performed via the device's touch screen. Originally, Android devices were bound to provide hardware buttons, but starting with Android 4.0, those buttons are gradually replaced with software buttons (displayed on the touch screen).

This prototype is built and tested with Android 4.0.

\subsection{Library Visualization}

\begin{itemize}
	\item Extraction of music metadata on the device \\\\
			\textbf{Input:} Access to a data store containing the device's music library metadata. \footnote{The app prototype utilizes a standard SQLite database in order to store data which can be persisted in order to reduce computation time, thus improving the user experience.}
			  \\
			\textbf{Algorithm:} Iterates through all artists and tracks in the device's music library.
			If an entity has not yet been registered in the app's database, parts of its metadata are 
			compiled and put into the database. \\
			\textbf{Output:} Local music metadata stored in the app's database.\\
			
	\item Matching of the device's music metadata with metadata from web sources \\\\
			\textbf{Input:} Local music metadata stored in the app's database.  \\
			\textbf{Algorithm:} Iterates through all local music metadata previously retrieved (artist, albums, titles...), and calls
			Last.fm's and Echonest's RESTful API to find matching entities - picking the first match as best match. These pieces
			of remote metadata are then stored in the app's database. \\
			\textbf{Output:} Remote music metadata stored in the app's database. \\
			
	\item Querying of Artist Similarity data from web sources \\\\
			\textbf{Input:} Local music metadata and matched metadata from remote web sources stored in the app's database. \\
			\textbf{Algorithm:} Iterates through all local and remote music metadata previously retrieved, and calls
			Last.fm's RESTful API to get the 100 most similar artists for each artist in the local database. \\
			\textbf{Output:} Artist similarity relations stored in the app's database. \\
			
	\item Completion of Artist Similarity data \\\\
			\textbf{Input:} Artist similarity relations stored in the app's database. \\
			\textbf{Algorithm:} Iterates through the previously retrieved artist similarity relations, and
			adds approximations for similarity relations which have not been found in the web API's results.
			These approximations are calculated as described in Section ~\ref{ch:computation}. \\
			\textbf{Output:} Complete artist similarity relations stored in the app's database. \\
			
	\item Laying out artists in 2D space with a Multi Dimensional Scaling (MDS) algorithm \\\\
			\textbf{Input:} Complete artist similarity relations stored in the app's database.   \\
			\textbf{Algorithm:} Applies a multistep (see sub-steps) algorithm which uses previously
			retrieved similarity data to position nodes resembling artists without overlappings.  \\
			\textbf{Output:} Graph structure of nodes resembling artists, laid out such that their position 
			indicates their similarity to each other. \\
			
		\begin{itemize}
			
			\item Building up of a distance matrix between artists \\\\
				\textbf{Input:} Complete artist similarity relations stored in the app's database. \\
				\textbf{Algorithm:} Iterates through all artist similarity relations, calculates a
				distance value (\emph{d = 1 - Similarity}, d $\in$ [0, 1], Similarity $\in$ [0, 1]), and writes it into
				a matrix data structure where both dimensions' labels consist of all existing artists. \\
				\textbf{Output:} Distance matrix of artists, based on their inverted similarities. \\
				
			\item Generation of a subset of artists and laying them out according to spring model forces	\\\\
				\textbf{Input:} Distance matrix of artists, based on their inverted similarities. \\
				\textbf{Algorithm:} Picks a random sample of artists of size $\sqrt{N}$ (N: number of all artists), assigns random positions to them,
				and applies a multi-dimensional scaling algorithm on them (see subsection 
				~\ref{subch:implementation-mds} later in this section). \\
				\textbf{Output:} Graph structure of nodes resembling artists (correctly positioned subset) \\
				
			\item Addition of the remaining artists, positioning them around the initial subset \\\\
				\textbf{Input:} Graph structure of nodes resembling artists (correctly positioned subset) \\
				\textbf{Algorithm:} Iterates through the remaining artist nodes and positions each on a position
				in the vicinity of its most similar artist (estimating which quadrant will be the best, as described in Chapter ~\ref{ch:computation}). \\
				\textbf{Output:} Graph structure of nodes resembling artists, many of them suboptimally positioned \\
				
			\item Application of spring model forces on all nodes for a few iterations \\\\
				\textbf{Input:} Graph structure of nodes resembling artists, many of them suboptimally positioned \\
				\textbf{Algorithm:} Applies the aforementioned multi-dimensional scaling algorithm on the whole graph of
				all artist nodes, thus reducing system stress \footnote{System stress is a metric for how well the current layout of a graph satisfies its internal forces. The higher the disconnect between the node's optimal distances and their actual distances is, the higher is the stress. One way to calculate stress is: S = $\sum_{n_i, n_j}^{n_N} ( Actual Distance(n_i, n_j) - Optimal Distance(n_i, n_j) ) ^ 2, n_i != n_j$} (finding a better position for each artist).  \\
				\textbf{Output:} Graph structure of nodes resembling artists, laid out such that their position 
				indicates their similarity to each other.\\
				
			\end{itemize}
				
	\item Removal of overlapping of artists' depictions in 2D space	\\\\
				\textbf{Input:} Graph structure of nodes resembling artists, laid out such that their position 
				indicates their similarity to each other. \\
				\textbf{Algorithm:} Empties out the graph, and re-adds the artist nodes back into it, one by one,
				while optionally moving nodes when they are added such that they do not overlap any other nodes. This
				movement is determined by the vector of both nodes' center coordinates and their amount
				of overlapping. For more details about this algorithm, see 
				~\ref{subch:implementation-overlapping} later in this section. \\
				\textbf{Output:} Graph structure of nodes resembling artists, laid out such that they don't 
				overlap each other and their position indicates their similarity to each other. \\
				
	\item Display of the laid out artists in OpenGL	\\\\
				\textbf{Input:} Graph structure of nodes resembling artists, laid out such that they don't 
				overlap each other and their position indicates their similarity to each other. \\
				\textbf{Algorithm:} Displays the graph on an OpenGL canvas (3D), by using the artists' images (in form
				of textures) and their names (rendered to textures). Sets the viewport and transformation
				matrices such that a 2D view is simulated, displaying artist nodes as viewed from above. \\
				\textbf{Output:} OpenGL view object and auxiliary system objects \\
				
	\item Continuous reaction to user actions (zooming, panning, tapping) \\\\
				\textbf{Input:} OpenGL view object and auxiliary system objects. \\
				\textbf{Algorithm:} Continuously reacts to user interface inputs, by moving the OpenGL canvas'
				pseudo-camera (i.e., manipulating the model transformation matrix) for zooming and panning.
				Marks an artist node as selected when the user taps onto it, and displays a context menu. \\
				\textbf{Output:} Updated view state
\end{itemize}

\subsection{Artist Discovery}

\begin{itemize}
	\item Queries last.fm for the N artists most similar to "'subject"'\\\\
				\textbf{Input:} "'Subject"' artist the user has selected for discovery. \\
				\textbf{Algorithm:} Queries Last.fm for the artists most similar to "'subject"', and returns
				an excerpt of those. \\
				\textbf{Output:} Excerpt of artists most similar to "'subject"'. \\
	\item Integration of the retrieved artists around "'subject"' in 2D space, at randomized but similar positions \\\\
				\textbf{Input:} Excerpt of artists most similar to "'subject"'. \\
				\textbf{Algorithm:} Applies a force-based layout algorithm on the collection of "'subject"' and
				its similar artists, such that the similar artists are arranged in a star around "'subject"'. \\
				\textbf{Output:} Graph structure of nodes resembling artists, laid out such that similar
				artists encircle "'subject"'. \\
	\item Continuous re-arrangement of the retrieved artists based on a force-based layout algorithm (also reacting to newly added similar artists) \\\\
				\textbf{Input:} Graph structure of nodes resembling artists, laid out such that similar
				artists encircle "'subject"'. \\
				\textbf{Algorithm:} As the user selects more artist nodes as "'subject"' and load
				its similar artists, this algorithm is then restarted, but the previous subjects and their
				similar artists are kept, and their positions adapted as needed - i.e., force-based layout
				calculation does not stop for those. \\
				\textbf{Output:} Updated graph structure of nodes resembling artists, laid out such that similar artists encircle "'subject"', also related to previously retrieved similar artists \\
\end{itemize}

\section{Illustrations of Algorithm Steps}

The previously described algorithms used for the composition of the App will in the following be  illustrated by screenshots of their outcome. These screenshots are based on an example library which the author of this thesis used while implementing, debugging, and testing the App. Many of the states depicted on the screenshots are not to be found in the actual App, because during the computational algorithms the current graph state is hidden from the user. Only Figure ~\ref{fig:screen_mds_10_after_all_uncollided_nodes} is a screenshot of the final version of the App. The other figures serve as pure illustration for this thesis.

\subsection{Before the Computation}

In figure ~\ref{fig:screen_mds_1_initial}, the initial graph state is shown - a loose collection of artist nodes strewn around the graph's origin in a random manner. At this point, no computation has yet been performed except the assignment of random positions (to avoid edge cases during the application of spring model forces later on, which arise when all nodes are located at the origin).

\begin{figure}[H]
  \centering
    \includegraphics[width=0.4\textwidth]{figures/screen_mds_1_initial}
  \caption{The initial graph state before MDS calculation}
  \label{fig:screen_mds_1_initial}
\end{figure}

\newpage
\subsection{After 5 Subset Iterations (MDS)}
\label{subsec:mds-after-five-subset-iterations}

As previously described in sections ~\ref{sec:mds-algorithm} and ~\ref{sec:algorithm-assembly}, the first steps in the App's MDS computation are:

\begin{enumerate}
	\item Generation of a subset of nodes, and
	\item Application of a number of spring model iterations on this subset.
\end{enumerate}

The screenshot depicted in figure ~\ref{fig:screen_mds_2_after_5_subset_iterations} shows the graph's state after five iterations of step 2. If compared to figure ~\ref{fig:screen_mds_1_initial}, it can be observed that four of the artist nodes have been moved to more outward positions.

\begin{figure}[H]
  \centering
    \includegraphics[width=0.4\textwidth]{figures/screen_mds_2_after_5_subset_iterations}
  \caption{Graph state after 5 iterations of the initial subset}
  \label{fig:screen_mds_2_after_5_subset_iterations}
\end{figure}

\newpage
\subsection{After 20 Subset Iterations (MDS)}

Similar to the previous figure, the following screenshot ~\ref{fig:screen_mds_3_after_20_subset_iterations} shows graph state during the second step (application of a number of spring model iterations on the initial subset) of MDS computation, but with 20 iterations of progress. It's easy to see that the four artist nodes (which have already been moved in figure ~\ref{fig:screen_mds_2_after_5_subset_iterations}) have been displaced even more.

\begin{figure}[H]
  \centering
    \includegraphics[width=0.4\textwidth]{figures/screen_mds_3_after_20_subset_iterations}
  \caption{Graph state after 20 spring force iterations of the initial subset}
  \label{fig:screen_mds_3_after_20_subset_iterations}
\end{figure}

\newpage
\subsection{After Placements of 5 Remaining Nodes (MDS)}

After spring model forces have been applied to the initial node subset, the remaining nodes (not being in the initial subset) are now placed in semantically sane positions. In figure ~\ref{fig:screen_mds_4_after_5_restnode_additions}, it can be observed that some nodes visible on the screen have been moved to positions which differ greatly from the old positions in the last screenshot. Because the placement algorithm is of low complexity, as has been shown in Section ~\ref{subsec:mds-selected-algorithm}, placements are performed in much shorter time than the previously described subset iterations.

\begin{figure}[H]
  \centering
    \includegraphics[width=0.4\textwidth]{figures/screen_mds_4_after_5_restnode_additions}
  \caption{Graph state after 5 placements of nodes outside the initial subset}
  \label{fig:screen_mds_4_after_5_restnode_additions}
\end{figure}

\newpage
\subsection{After Placements of All Remaining Nodes (MDS)}

Figure ~\ref{fig:screen_mds_5_after_all_restnode_additions} shows the graph's state after all nodes not in the initial subset have been placed in approximated positions. Although all nodes have been displaced at least once, this is an intermediate state, not yet resembling the algorithm's final outcome. Most nodes should be at least near their optimal position, minimizing system stress, but tests have shown that some nodes will be displaced by much in the following placement corrections. Due to the nature of the performed placement approximation, the such placed nodes take into account only the most similar node - yet there may be other nodes at an entirely different position in the graph to which the placed node is also similar.

\begin{figure}[H]
  \centering
    \includegraphics[width=0.4\textwidth]{figures/screen_mds_5_after_all_restnode_additions}
  \caption{Graph state after placements of all nodes outside the initial subset}
  \label{fig:screen_mds_5_after_all_restnode_additions}
\end{figure}

\newpage
\subsection{After 5 Placement Correction Iterations (MDS)}

Similar to the beginning of the calculations (depicted in Section ~\ref{subsec:mds-after-five-subset-iterations}), the spring model algorithm is again applied to the graph, but on all nodes at once. The previously approximated positions for many of the nodes have to be corrected (i.e., system stress has to be reduced) for the produced layout to increase significance. Some or many of the nodes are even at the wrong side of the graph, judging by the forces enacted by all other nodes. Application of a limited number of spring model iterations has the potential to improve the expressiveness of the layout greatly. Figure ~\ref{fig:screen_mds_6_after_5_cleanup_iterations} displays graph state after five spring model iterations.

\begin{figure}[H]
  \centering
    \includegraphics[width=0.4\textwidth]{figures/screen_mds_6_after_5_cleanup_iterations}
  \caption{Graph state after 5 spring model iterations of all nodes}
  \label{fig:screen_mds_6_after_5_cleanup_iterations}
\end{figure}

\newpage
\subsection{After 10 Placement Correction Iterations (MDS)}
\label{subsec:mds-after-ten-placement-iterations}

After 10 spring model iterations, the resulting layout is supposed to sufficiently satisfy the graph's similarity forces. The result is shown in figure ~\ref{fig:screen_mds_7_after_10_cleanup_iterations}, which also resembles the final outcome of the MDS algorithm. 
The graph's nodes have been laid out such that their centers' positions reduce system stress - not giving any heed to overlappings. Therefore, the process does not end here, but these overlappings have to be eliminated.

\begin{figure}[H]
  \centering
    \includegraphics[width=0.4\textwidth]{figures/screen_mds_7_after_10_cleanup_iterations}
  \caption{Graph state after 10 spring force iterations of all nodes}
  \label{fig:screen_mds_7_after_10_cleanup_iterations}
\end{figure}

\newpage
\subsection{After Removal of Node Overlappings from 5 Nodes}

By applying the anti-overlap algorithm described in Section ~\ref{sec:removal-node-overlapping}, overlapping artist nodes are separated from each other. Figure ~\ref{fig:screen_mds_8_after_5_uncollided_nodes} shows the graph's state after five nodes have been processed, i.e. they have been repositioned such that they keep a certain margin to any other nodes.

\begin{figure}[H]
  \centering
    \includegraphics[width=0.4\textwidth]{figures/screen_mds_8_after_5_uncollided_nodes}
  \caption{Graph state after removal of node overlappings from 5 nodes}
  \label{fig:screen_mds_8_after_5_uncollided_nodes}
\end{figure}

\newpage
\subsection{After Removal of Node Overlappings from Half of All Nodes}

As a continuation of the last screenshot, the following figure ~\ref{fig:screen_mds_9_after_half_uncollided_nodes} depicts the graph's state after half of all artist nodes have been repositioned to avoid overlappings.

\begin{figure}[H]
  \centering
    \includegraphics[width=0.4\textwidth]{figures/screen_mds_9_after_half_uncollided_nodes}
  \caption{Graph state after removal of node overlappings from half of all nodes}
  \label{fig:screen_mds_9_after_half_uncollided_nodes}
\end{figure}

\newpage
\subsection{After Removal of Node Overlappings from All Nodes}

Screenshot ~\ref{fig:screen_mds_10_after_all_uncollided_nodes} shows the final state of the graph, at the end of all computations. This is a compromise between the intermediate result shown in subSection ~\ref{subsec:mds-after-ten-placement-iterations}, and a user-friendly (easy to grasp) representation of the graph. Clearly, system stress has been increased by removal of node overlappings; but, the process has made the MDS algorithm's results readable and easily understandable. The resulting margin between the nodes is subject to adjustable parameters, leaving room for further optimization.

In the actual App implementation, this is the first state displayed to the user - all previous states are hidden from her. Subsequently, the App reacts to touch gestures in order to enable navigation and exploration of the structure on small screens (it's understood that screenshot~\ref{fig:screen_mds_10_after_all_uncollided_nodes} does not show all artists of the graph).

\begin{figure}[H]
  \centering
    \includegraphics[width=0.4\textwidth]{figures/screen_mds_10_after_all_uncollided_nodes}
  \caption{Graph state after removal of node overlappings from all nodes}
  \label{fig:screen_mds_10_after_all_uncollided_nodes}
\end{figure}

\section{Retrieval of Music Metadata}

\subsection{Querying of Music Metadata on the Device}

Android has a cursor-based query system for multimedia metadata (kept up-to-date transparently by the
operation system). Creation of a cursor for all artists on the device is performed by program code like this:

\begin{verbatim}
Cursor artistCursor = mContext.getContentResolver().query(
	MediaStore.Audio.Artists.EXTERNAL_CONTENT_URI,
    artistProjection, null, null, null);
\end{verbatim}

Since the returned metadata also contains a unique key for each multimedia file, metadata can be
persisted in a database and later be reused without obstacles.
Metadata records themselves contain as much data as the user or the file-generating utility has defined
before the file was copied onto the device - clearly, files may not have any metadata available at all.

In the implementation of the App, such a cursor is traversed over all available music titles, and several entities are derived:

\begin{itemize}
	\item Artist,
	\item Album, and
	\item Track title.
\end{itemize}

While these entities are created, the implementation checks whether they already exist, and skips creation accordingly. Retrieved data is then stored in the App's on-device database.

\subsection{Retrieval of Music Metadata from Web Sources}

Last.fm \cite{url:lastfm} and Echonest \cite{url:echonest} are the de facto standards for music metadata retrieval in the world wide web, 
at the time of writing of this paper. The author has chosen to use both of these services for retrieval 
of semantic metadata for the implementation. 

After the device's music titles and their metadata have been retrieved, their metadata has to be augmented or corrected with the normalized data from external sources - Last.fm and Echonest. To ensure a stable mapping from on-device to remote music metadata records, these are fetched up front. For every artist, album, and track the App has retrieved from the device, a match is searched for in web sources. Search for matches is performed by sending an ordinary search query to the web sources, and metadata records are returned as a result. Excerpts of the acquired records are then stored in the App's on-device database.

\section{Retrieval of Similarity Data}

Ideally, the retrieval of similarities between artists should provide an exhaustive list of similarities between any two artists. But, as a real-world implementation must make do with actuality, workarounds had to be found which provide approximations to artist similarities.
Echonest's artist similarity results contain no similarity metric, but only the implicit ranking of artists. Therefore, the author of this thesis decided \textbf{not to use Echonest's similarity metrics}.

Last.fm's artist similarity data is, in contrast to Echonest, augmented with accurate similarity measures in the range of $[0 .. 1]$. But, it is not possible to query Last.fm for a certain similarity relationship between two certain artists - instead, the top 100 similar artists for a certain artist can be retrieved. It's clear that this way, many artist-to-artist relations in a music collection will not receive a similarity measure. Instead, a dedicated algorithm has to approximate similarity values which were not provided by Last.fm.

As Last.fm provides similarity value lists per artist ("'subject"'), it can be assumed that every relation to an artist not on the list has a similarity value within the interval \emph{[0 .. x], x = lowest known similarity of "'subject"' to any other artist}. Not having any more details at hand than this fact, the expected value of such an unknown similarity value is $x / 2$ - the author of this thesis decided to use this value as an approximation. In algorithm listing ~\ref{alg:similarity-approximation}, the algorithm to interpolate similarity values (which is being used in the App's implementation) is described. 

\begin{algorithm}[ht]
\SetKwData{SimilarArtists}{similarArtists}
\SetKwData{LowestMatch}{lowestMatch}
\SetKwData{ArtistOnDevice}{artistOnDevice}
\SetKwData{InnerArtistOnDevice}{innerArtistOnDevice}
\SetKwData{SimilarArtist}{similarArtist}
\SetKwData{ArtistSimilarity}{artistSimilarity}
\SetKwData{AllArtistSimilarities}{allArtistSimilarities}
\SetKwFunction{SizeOf}{sizeof}
\SetKwFunction{GetSimilarArtists}{getSimilarArtists}
\SetKwFunction{GetSimilarityMatch}{getSimilarityMatch}
\SetKwFunction{MakeArtistSimilarity}{makeArtistSimilarity}
\SetKwFunction{Matches}{matches}
\SetKwFunction{Put}{put}
\SetKwInOut{Input}{input}
\SetKwInOut{Output}{output}

\Input{List of all artists' metadata stored on the device}
\Output{List of similarities between each artist}

\BlankLine

\For{\ArtistOnDevice$\leftarrow$ firstArtist \KwTo lastArtist}{
  \SimilarArtists$\leftarrow$ \GetSimilarArtists(\ArtistOnDevice)\;
  \For{\InnerArtistOnDevice$\leftarrow$ firstArtist \KwTo lastArtist}{
    \If{\SizeOf{\SimilarArtists} $==$ 0}{\LowestMatch$\leftarrow$ 0\;}
    \Else{\LowestMatch$\leftarrow$ float-max-value\;}

    \For{\SimilarArtist$\leftarrow$ \SimilarArtists$.first$ \KwTo \SimilarArtists$.last$}{
      \If{\GetSimilarityMatch{\SimilarArtist} $<$ \LowestMatch}
         {\LowestMatch$\leftarrow$ \GetSimilarityMatch{\SimilarArtist}\;}
      \If{\Matches{\SimilarArtist, \InnerArtistOnDevice}}
        {\ArtistSimilarity$\leftarrow$ \MakeArtistSimilarity{\ArtistOnDevice, 
          \InnerArtistOnDevice, \GetSimilarityMatch{\SimilarArtist}}\;
        \textbf{break}\;
	  }
    }

	\If{\SizeOf{\SimilarArtists} $==$ 0}{\ArtistSimilarity$\leftarrow$ \MakeArtistSimilarity{\ArtistOnDevice, 
      \InnerArtistOnDevice, 0}\;}
    \ElseIf{\ArtistSimilarity $==$ 0}{\ArtistSimilarity$\leftarrow$ \MakeArtistSimilarity{\ArtistOnDevice, 
      \InnerArtistOnDevice, \LowestMatch $/ 2$}\;}

	\Put{\AllArtistSimilarities, \ArtistSimilarity}\;
  }
}
\Return \AllArtistSimilarities\;
\BlankLine
\caption{Similarity Approximation Algorithm}\label{alg:similarity-approximation}
\end{algorithm}

\section{Implementation of Multidimensional Scaling}
\label{subch:implementation-mds}

The selected MDS algorithm has already been discussed broadly in Chapter ~\ref{ch:computation}. Implementation of this algorithm required the creation of a number of helper and data classes, but on the whole, the implementation follows the pseudocode from Chapter ~\ref{ch:computation} closely. To better illustrate step 3. from the mentioned pseudocode, the implementation part is included in the algorithm listing ~\ref{alg:nearest-neighbor-positioning}.

\begin{algorithm}[ht]
\SetKwData{Subject}{subject}
\SetKwData{NearestNode}{nearestNode}
\SetKwData{CurrentSubsetNodes}{currentSubsetNodes}
\SetKwData{DistanceToNearestNode}{distanceToNN}
\SetKwData{UpperRightQuadrant}{urQuadrant}
\SetKwData{LowerRightQuadrant}{lrQuadrant}
\SetKwData{UpperLeftQuadrant}{ulQuadrant}
\SetKwData{LowerLeftQuadrant}{llQuadrant}
\SetKwData{UpperRightStress}{urStress}
\SetKwData{LowerRightStress}{lrStress}
\SetKwData{UpperLeftStress}{ulStress}
\SetKwData{LowerLeftStress}{llStress}
\SetKwData{CurrentSubsetNode}{currentSubsetNode}
\SetKwData{MinStress}{minStress}
\SetKwData{SumOfForcesOnSubject}{sumOfForcesOnSubject}
\SetKwData{InitialSubset}{initialSubset}
\SetKwFunction{Add}{add}
\SetKwFunction{GetNearestNode}{getNearestNode}
\SetKwFunction{GetDistanceBetween}{getDistanceBetween}
\SetKwFunction{GetPointInQuadrant}{getPointInQuadrant}
\SetKwFunction{GetStress}{getStress}
\SetKwFunction{Min}{min}
\SetKwFunction{SetPosition}{setPosition}
\SetKwFunction{MakeVector}{makeVector}
\SetKwFunction{Force}{force}
\SetKwFunction{Displace}{displace}
\SetKwInOut{Input}{input}
\SetKwInOut{Output}{output}


\Input{Subject [the node to be positioned near any other node]}
\Input{InitialSubset [the initial nodes subset]}
\Input{CurrentSubsetNodes [the nodes subset incrementally populated]}
\Output{No return value; Subject node has been optimally positioned}

\BlankLine

\NearestNode$\leftarrow$ \GetNearestNode{\Subject, \CurrentSubsetNodes}\;
\DistanceToNearestNode$\leftarrow$ \GetDistanceBetween{\Subject, \NearestNode} $*$ DISTANCE-CONSTANT\;

\UpperRightQuadrant$\leftarrow$ \GetPointInQuadrant{1, 1, \DistanceToNearestNode, \NearestNode}\;
\LowerRightQuadrant$\leftarrow$ \GetPointInQuadrant{1, -1, \DistanceToNearestNode, \NearestNode}\;
\UpperLeftQuadrant$\leftarrow$ \GetPointInQuadrant{-1, 1, \DistanceToNearestNode, \NearestNode}\;
\LowerLeftQuadrant$\leftarrow$ \GetPointInQuadrant{-1, -1, \DistanceToNearestNode, \NearestNode}\;

\tcc{Calculate Stress for upper \& lower, right \& left quadrants...}

\MinStress$\leftarrow$ \Min{\UpperRightStress, \LowerRightStress, \UpperLeftStress, \LowerLeftStress}\;

\If{\UpperRightStress $==$ \MinStress}{\SetPosition{\Subject, \UpperRightQuadrant}\;}
\ElseIf{\LowerRightStress $==$ \MinStress}{\SetPosition{\Subject, \LowerRightQuadrant}\;}
\ElseIf{\UpperLeftStress $==$ \MinStress}{\SetPosition{\Subject, \UpperLeftQuadrant}\;}
\Else{\SetPosition{\Subject, \LowerLeftQuadrant}\;}

\For{i$\leftarrow$ 1 \KwTo QUADRANT-REFINING-ITERATIONS}{
  \SumOfForcesOnSubject $\leftarrow$ \MakeVector\;
  \For{$node\leftarrow$ \InitialSubset$.first$ \KwTo \InitialSubset$.last$}{
     \Add{\SumOfForcesOnSubject, \Force{\Subject, $node$}}\;
  }
  \Displace{\Subject, \SumOfForcesOnSubject}\;
}

\BlankLine
\caption{Nearest-Neighbor Positioning Algorithm}
\label{alg:nearest-neighbor-positioning}
\end{algorithm}

\section{Implementation of Removal of Node Overlappings}
\label{subch:implementation-overlapping}

The algorithm used for the removal of node overlappings has been shown in Section ~\ref{ch:visualization}. The actual implementation required some pragmatic changes, therefore the code is listed in the algorithm listing ~\ref{alg:removal-node-overlappings}.

\begin{algorithm}[ht]
\SetKwData{Subject}{subject}
\SetKwData{SubjectDisplacementVector}{subjectDisplacementVector}
\SetKwData{NodeCentersDistance}{nodeCentersDistance}
\SetKwData{CollisionCandidate}{collisionCandidate}
\SetKwData{RandomMargin}{randomMargin}
\SetKwData{NodesWithoutOverlap}{nodesWithoutOverlap}
\SetKwFunction{Randomize}{randomize}
\SetKwFunction{GetEuclideanDistance}{getEuclideanDistance}
\SetKwFunction{MakeVector}{makeVector}
\SetKwFunction{SetVectorLength}{setVectorLength}
\SetKwFunction{Displace}{displace}
\SetKwInOut{Input}{input}
\SetKwInOut{Output}{output}


\Input{Subject [node to be freed from overlappings with others]}
\Input{NodesWithoutOverlap [nodes to which this algorithm has been applied]}
\Output{No return value; Subject node has been freed of overlappings}

\BlankLine

  \For{i$\leftarrow$ 0 \KwTo ITERATIONS}{
    \For{\CollisionCandidate$\leftarrow$ \NodesWithoutOverlap$.first$ \KwTo \NodesWithoutOverlap$.last$}{
      \NodeCentersDistance$\leftarrow$ \GetEuclideanDistance{\Subject, \CollisionCandidate}\;
      \RandomMargin$\leftarrow$ \Randomize{}\;

\tcc{NODES-SIZE: diagonal through an artist's depiction square, the maximally needed displacement
	  to separate two overlapped artist nodes.}
	
      \If{\NodeCentersDistance $< NODES-SIZE +$ \RandomMargin}{
        \SubjectDisplacementVector$\leftarrow$ \MakeVector{\CollisionCandidate, \Subject}\;
		\SetVectorLength{\SubjectDisplacementVector, NODES-SIZE $-$ \NodeCentersDistance $+$ \Randomize{}}\;
        \Displace{\Subject, \SubjectDisplacementVector}\;
      }
    }
  }

\BlankLine
\caption{Removal of Node Overlappings Algorithm}
\label{alg:removal-node-overlappings}
\end{algorithm}


The optimized algorithm has a predefined number of iterations, by the end of which a node should no longer overlap any other nodes. This number has to be chosen carefully - too high and the overall computation duration will increase linearly, too low and not all node overlappings will be removed.

\section{Visualization Details}

Apart from the previously described computational algorithms, the App features a number of components or behavior not contained in the Android operating system. In the following, the most interesting features aiding the visualization of content will be described.

\subsection{Drawing with OpenGL}

Android provides App developers with the possibility to implement three-dimensional viewports in OpenGL ES \cite{url:opengles}, which is a downsized version of ordinary OpenGL and meant for implementation in handheld devices. OpenGL is a specification which is used as a blueprint by operating systems vendors and GPU producers alike. An OpenGL context can be seen as a state-machine which is manipulated by external API calls.

While the prototype shall implement a 2D visualization, its implementation in OpenGL (which is a 3D drawing specification) is necessary to provide a reasonably high framerate. Early prototype tests with a strict 2D implementation (Android 2D canvas drawing) showed that image rendering let the framerate drop considerably, so that viewport zooming, panning, and animations were no longer smooth to the human eye. The app's usability suffered from this, and so the prototype was rebuilt using OpenGL. The reason why OpenGL performs better in this context is that GPUs are better suited for handling images (textures) than CPUs, because their architecture and instruction sets are primarily dedicated to rendering.

In order to be able to employ OpenGL for graph rendering, the author of this thesis had to create a number of abstract meta classes and find a way to resemble user interactions in the drawn 3D picture. As mentioned before, the objective was to draw pseudo-2D, such that all music objects are displayed as pictures, viewed from the top. Accordingly, the viewport has to move sideways when the user moves one finger over the touchscreen, and it has to change its distance to the graph objects when the user zooms.

\subsection{Touchscreen Handling}

With the advent of smartphones, strong conventions have been established by phone vendors which determine how users may interact with the smartphone. Touchscreen technology provides a more immediate way of interaction than previous systems, allowing users to seemingly interact with the very objects they want to manipulate (as opposed to moving views and cursors with hardware buttons).
There are three touchscreen gestures supported by the App's implementation:

\begin{itemize}
	\item \textbf{Panning/Scrolling} - The user taps the finger onto the screen surface, does not let 
	go, and pulls the finger across the surface. As long as the finger does not part from the surface, 
	the "'pan/scroll"' is active.
	\item \textbf{Zooming} - The user rests two fingers on the screen surface, and changes the distance
	between her finger tips. If the distance decreases, then the zoom factor will increase; and vice versa.
	Ideally, the touched points would always stay right under the user's finger tips, but in the built
	App prototype, this has not been achieved, because of the three-dimensional nature of the OpenGL
	rendering process.
	\item \textbf{Tapping} - The user taps her finger onto the screen surface at a point on which the
	desired object is located, and lets go again immediately. The App then reacts to this interaction
	with an adequate response or action, depending on the current state of the user interface.
\end{itemize}

\subsection{Animations}

To make transitions between view states in the App smoother and easier to follow for users, animations have been implemented to do so. It has been shown in an empirical study that comprehension of changes can be improved by adding animations ~\cite{Schlienger:2007}.

\textbf{Whole-screen transition} - If the user chooses to display an artist's albums, the transition to the next Activity (fullscreen Android layout component) is implemented as a fade-over animation, meaning that the second screen is added as an overlay and its alpha channel is animated from 0 to 1. This way, the user is able to notice the change of context without being disturbed by untraceable changes.

\textbf{Artist Node animation} - If the user selects an artist by tapping, the artist's image depiction is moved on the z-axis towards the virtual camera - appearing nearer to the viewport. This puts an emphasis on the selected artist and makes for a pleasing optical effect. As OpenGL is a low-level framework, animations like this have to be implemented by the developer - keeping track of animation start and projected end time, and determining the state for every newly drawn frame.

\textbf{Context-related graph area darkening} - If the user chooses to display an artist's related (similar) artists, the graph area darkens over all other currently displayed artists, to put an emphasis on the selected artist and its related artists. This effect is achieving by adding a rectangle between the emphasized artists and the others, which is at first transparent and then gains opacity through an animation.

\section{Structure of the App}

The prototypical App implementation is targeted at the Android operating system. In this section, some implementation specifics will be given for better reproducability.

\subsection{Activities}

The App's UI stack consists of two Activities (screens):

\begin{itemize}
	\item \textbf{Loading Activity} - Fetching metadata from the internal storage and web sources, and compilation of the same is a lengthy process, and therefore a dedicated Activity exists in the App, displaying progress indicators.
	\item \textbf{Artists Activity} - The main screen of the App, showing all artists in the user's music collection, laid out such that nearness between artists implicates similarity.
	\item \textbf{Albums Activity} - The secondary screen, displaying an artist the user has selected on the previous screen, along with their albums.
\end{itemize}

\subsection{Classes and Packages}

In the following, figures of the App's class and package structure will be depicted. The reader can refer to their descriptions in the figures' captions.

\begin{figure}[H]
  \centering
    \fbox{\includegraphics[width=0.7\textwidth]{figures/package-main}}
  \caption{The App's main package, containing Activities, the root App class (a singleton in Android), and a generic graph view class.}
  \label{fig:package-main}
\end{figure}

\begin{figure}[H]
  \centering
    \fbox{\includegraphics[width=0.7\textwidth]{figures/package-computation}}
  \caption{Package containing all classes and interfaces related to computation - MDS layout, spring layout, node overlap removal, and intermediate helper computations.}
  \label{fig:package-computation}
\end{figure}

\begin{figure}[H]
  \centering
    \fbox{\includegraphics[width=0.7\textwidth]{figures/package-download}}
  \caption{Classes related to download of content, like images.}
  \label{fig:package-download}
\end{figure}

\begin{figure}[H]
  \centering
    \fbox{\includegraphics[width=0.7\textwidth]{figures/package-graph}}
  \caption{Graph-related and auxiliary classes, with their functionality ranging from graph nodes and graph state retention to animation state helpers.}
  \label{fig:package-graph}
\end{figure}

\begin{figure}[H]
  \centering
    \fbox{\includegraphics[width=0.7\textwidth]{figures/package-glhelper}}
  \caption{Package containing OpenGL helper classes, as needed for the use of OpenGL ES in Android.}
  \label{fig:package-glhelper}
\end{figure}

\begin{figure}[H]
  \centering
    \fbox{\includegraphics[width=0.7\textwidth]{figures/package-manager}}
  \caption{Management classes responsible for querying and storing music metadata on the device and on web sources.}
  \label{fig:package-manager}
\end{figure}

\begin{figure}[H]
  \centering
    \fbox{\includegraphics[width=0.7\textwidth]{figures/package-model}}
  \caption{Package with model classes which hold music metadata from both the device and web sources.}
  \label{fig:package-model}
\end{figure}

\begin{figure}[H]
  \centering
    \fbox{\includegraphics[width=0.7\textwidth]{figures/package-util}}
  \caption{Utility components which provide functionality to the rest of the App's classes, most of them being generic and exchangeable.}
  \label{fig:package-util}
\end{figure}

\begin{figure}[H]
  \centering
    \fbox{\includegraphics[width=0.7\textwidth]{figures/package-widget}}
  \caption{Package containing widget classes which could be used in most Android apps - currently containing only one such component.}
  \label{fig:package-widget}
\end{figure}

\subsection{Third Party Libraries}

\begin{itemize}
	
	\item \textbf{jEn-api}, an Echonest API library for Java, also working in Android apps. \\
License: \emph{New BSD License}

	\item \textbf{lastfm-java}, an unofficial Last.fm API library for Java, also working in Android apps. \\
License: \emph{New BSD License}

	\item \textbf{ORMLite}, a low-profile object relational mapper for SQLite in Java, also working in Android apps. \\
License: \emph{ISC License}

	\item \textbf{JSON.simple}, a JSON (JavaScript Object Notation) parser for Java, also working in Android apps. \\
License: \emph{Apache 2.0 License}

	\item \textbf{Android Support Library v4}, a library provided by Google to enable more recent Android features for older OS versions. \\
License: \emph{Apache 2.0 License}

	\item \textbf{Android Annotations}, a compile-time library which generates code from Java annotations, to allow pseudo-dependency injection and more advanced features. \\
License: \emph{Apache 2.0 License}

\end{itemize}

\section{Summary of this Section}

This chapter has explained the components, algorithms, and concepts used to construct a prototype demonstrating the visualization of artist similarity, runnable on mobile Android devices.

Algorithms and the flow of information between them has been described, both for the visualization of a music library (on-device metadata extraction, matching, web source metadata extraction and interpolation, layout generation, removal of node overlappings, display of the graph to the user), and for artist discovery (querying of related artists from web sources, their integration into the layout, and continuous rearrangement via a force-based layout algorithm).
Thereafter, different states of the App prototype while executing the previously described algorithms have been illustrated, using screenshots.

Retrieval of music metadata from the user's device and web sources, and retrieval of similarity data from web sources has been described in detail. Since this similarity data may be incomplete, an interpolation algorithm for unknown values has been given.
A part of the MDS algorithm (already described in length in Chapter ~\ref{ch:computation}), the  positioning of graph nodes based on system stress minimization, has been detailed as pseudocode. The algorithm for the removal of node overlappings in the graph was also shown.
To provide some details about visualization and the App's user interaction model, OpenGL drawing, touchscreen gestures, and animations were elaborated on.

Finally, a short introduction to the Android operating system was given, and the prototype App's structure (Activities and other classes) and third party libraries were detailed.