Music has reportedly been an integral part of our lives for thousands of years. It can even be argued that animals, like birds, use some kind of music as part of their courtship behavior. Just like colors and odors are used to communicate information, like visual displays of hazards or olfactory hints of toxicity, sound is an excellent medium for messages of all kinds. Music has therefore been used as a means of transmitting and preserving information in the form of vocal songs, or rhythmic sequences of artificial sounds which describe environmental events or circumstances - and still is. As mankind's technical abilities evolved, their efforts to manufacture ever more sophisticated musical instruments produced a multitude of ways to make music. Many-voiced compositions started to arise, and more recent pieces of music are generally a mix of a large amount of sound sources, both natural and artificial. This complexity made it necessary to bring music into forms which are easier to reproduce than mere imitation. Through normalization (establishing of musical scales and standard frequencies for notes) and notation, musical compositions could be distributed and reproduced by anybody who knew how to read these notations. As more and more artists got used to certain notational methods, the methods evolved, and nowadays we are left with only a handful of ways to reproduce live music.

As music is viewed as an important source of information and entertainment, humanity has long strived to bring pieces of music into more reproducible forms. Live music is most often not an option - it's expensive, and not easy to get by. Therefore, technical solutions have been searched for and found. Advancements in mechanical engineering made it possible to capture live music on physical media, like wax cylinders or, later on, disks made of shellac. While the introduction of electrical components aided in the improvement of the produced media, the physical properties of the storage material made it nearly impossible to achieve a copy which is indistinguishable from the original recording. Moreover, physical media are inherently lossy, and after more or less playback cycles, the qualitative gap between the copy and the reference would widen.

The arguably most important advancement in music (and other media) reproduction happened with the introduction of digitalization. The same electrical signals which were previously converted into a groove in a shellac disk were now sampled and turned into numbers, and stored in a binary format. As the sampling rates and data rate could be increased almost arbitrarily, the quality of digitally stored recordings quickly convinced consumers of the superiority over analog recordings. But, the preferred transfer media still were physical objects, like CDs or cassettes. As the distribution of physical media is subpar compared to the delivery over digital networks, the Internet revolutionized the process of music distribution again. The transition of the mass market to distribution over the Internet is not completed at the time of the writing of this thesis, but it seems like a possible near future that physical transfer media will soon be obsolete. Currently, the state of the art of end user music distribution is streaming, which means that audio data is retrieved from an Internet server on demand, and audio files only reside on the consumer's hard disk or memory for the sake of caching and (potentially) redistribution to other consumers via P2P technology. Since these on-disk caches can be encrypted, it is possible for music distributors to lock-out the consumer from access to the downloaded audio files, thus making subscription-based consumption models possible. Companies like Rdio or Spotify make millions of songs from hundreds of thousands of artists available to each consumer, for a considerably small monthly fee. Compared to the amount of music available to common people just a hundred years ago (read: recordings of just the most important artists, printed on bulky shellac disks, sold at high prices), the increase in availability of high-quality content has been substantial.

In times of shellac disks, CDs, or even digital music collections on computer hard-drives or USB storage, many people had a mental model of their music collection, i.e., they knew what pieces of music they owned, and how to find them. They maybe had established their own ordering mechanisms, like ordering disks by alphabet or genre, or copied music files into nested hard-drive folders, or imported their metadata into music playback software with a full-text search algorithm. While there is an individual memory capacity for every person which limits the amount of songs one can remember, music collections generally just did not tend to grow so large such that one could not tell whether a song was in her collection or not. While ownership is a misleading term in this context (because songs are owned by the copyright holder, but not the media holder), people were used to say that they own their music collection. Ownership implies a certain knowledge of its contents - people basically hand-selected (either literally, or virtually) songs or albums into their collections. With the advent of large-scale file sharing and streaming services, which expose people to millions of songs and albums, mental models for the whole collection are not possible for ordinary humans to form, considering memory and time capacities. From a user perspective, it would not even make much sense to memorize every song from all of them - most people will never be able to consume so much content, and won't want to, because their musical taste is only satisfied by a fraction of the available songs. Clearly, the exposure to very large song collections has created its own new classes of problems: music discoverability and re-forming of mental models of music collections.

A mental model is the projection of an external system into a user's brain. It reflects the state of understanding of a system which an individual currently has, and it is built up by interacting with the system \cite{gentner1983mental}. Since humans are not physically connected to an abstract system like a machine, program source code, or a music collection, they have to form a mental model in order to efficiently navigate in it without having to use their senses all the time. A person who has a solid understanding of her music collection, and who might even be able to recapitulate large parts of it without access to the music storage system, has a strong mental model of the collection. If the user adds songs to her own music collection, they are also added to her mental projection of the collection. In order to make well-informed judgements about a system (e.g., "'Which artist in my collection is most similar to the Beatles, whom I like so well?"') without a huge mental overhead, the system needs to be reasonably well projected into its mental model. Many such judgements can be taken over by software features - a full text search functionality makes it unnecessary to memorize all artists in a collection. However, more sophisticated queries which make use of a user's individual knowledge or opinion (e.g. "'There is this band who have a similar keyboard sound like Foreigner - find this band in my music collection!"') are harder to satisfy by software, and well-formed mental models are still necessary for these use cases.

As mentioned before, it is not feasible for ordinary humans to form a mental model of a collection of millions of songs, due to memory and time constraints. The only way to deal with a very large music collection is therefore its reduction, or creation of excerpts from it. The streaming service Spotify has tried to solve this problem from two angles: Users create their own subsets via the creation of personal playlists, and a special Radio functionality tries to make the forming of a mental model obsolete by taking away users' choices and judgements. Cross-references between similar artists also try to assist the user in navigating the music collection in a semantic way, which would else-wise not be possible due to the lack of a reasonable mental model. However, these solutions don't offer all the benefits of an almost complete mental projection of a collection.

A very important component influencing the mental model of the user is the software user interface. In times of physical media, users often created their own ordering systems, as has previously been mentioned. However, large digital music collections on end users' hard drives have created the need for more durable ordering systems, and digital software has proven to be sufficiently flexible to take over this task. Instead of writing down the names of CDs, shellac media, or cassettes, modern software can extract digital music metadata automatically (or let the user enter it), and even fetch digital artist and album art from open Internet sources. It can safely be assumed that nowadays end-user software is the most convenient way of keeping in order a digital music collection. For this reason, a plethora of music software for all PC and mobile platforms has been created - recently, with the spread of open programming environments for mobile platforms, a simple music playback app can be created within a single day. Since software ideally tries to satisfy a number of use cases, most music program have a slightly different angle on user perspective. Obviously, different user interfaces are targeted at different audiences, but there are a few functionalities and concepts which seem to have proven useful and therefore have become a convention. For example, many music library organization or playback software provide not only one, but multiple ways of displaying the same collection, ranging from simple list-based, over image-assisted, to three-dimensional representations. Other applications for the professional sector like live event management have custom tailored representations which support their users' management and playback workflow.

Music software interfaces have also experienced an evolution until they reached the current level of sophistication. Early playback software was purely file-based and did sometimes not provide more functionality than opening a sound file from a DOS or Unix terminal and stop it. Scrubbing and fast-seeking were soon added, as was visual feedback on the current playback status. At this point, digital audio software had already become more convenient than most physical media playback devices, where users could not clearly tell at what position the playback was currently at. With the inception of graphical (window-based) operating systems and increasing monitor resolutions, the possibilities for the design of playback software grew, and so did the options for graphical representation of music libraries - extracted metadata could be presented in new ways, and increasing processing power made full-text metadata search a convention. It seems that the development of new collection visualizations soon declined thereafter, and unique inventions like iTunes' cover flow visualization nowadays are more the exception than the rule. As mentioned before, the paradigm change from on-site storage to cloud- or streaming services is problematic from a user perspective, because users can't realistically form complete mental models of the streaming service's music collection. Since visualization forms have not evolved much since, it is obvious that the optimal solution for the presentation of excerpts of big collections might not have been found yet. Services like Spotify apply hybrid interaction models of list-based browsing, additional apps from a specialized store, cross-references to related music, playlists - but it is well possible that alternative forms of visualization provide a better user experience.

Nearly every form of visualization can be used for music or music collections. Temporal (real-time) visualizations like histograms or fractals are often applied to give the user an understanding of a music stream's current or recent properties, like its frequency distribution, volume, or mood. Most modern music playback software has some form of artistic temporal visualization built-in, to augment the auditory stimulus with a pleasing visual experience. On the other hand, absolute or static visualizations are used to let the user search and browse visually, or form a mental model of a music collection. The objective of those is to present music objects (artists, albums, or titles) as some form of object, be it a pure text item in a list or a highly complex, animated, three-dimensional object. Abstractions of musical objects, such as the categorization or classification of a whole collection can help the user to get a grasp of the collection's contents even without displaying the concrete objects, as was demonstrated in \cite{Rauber:2004}. Three-dimensional interfaces obviously imitate the real world in an immediate way. While it is not yet possible to create photo-realistic realtime environments in 3D on desktop computers, modern CPUs and GPUs nowadays allow visualizations which are sufficiently realistic to avoid misinterpretations by the user. In \cite{Dittenbach:2007}, such a three-dimensional interface for music collections was presented. However, in the context of pragmatic use cases like the browsing or searching of artists in a collection, two-dimensional visualizations seem to be more promising than 3D, because they don't require the simulation of depth (third dimension). The natural movement paradigm is limited to up/down and left/right. This also accommodates the increasing number of touch interfaces in use, as two-dimensionality allows a seemingly direct manipulation of the presented collection space, through swiping, zooming, and panning touch gestures. An important upside of two-dimensionality as compared to a pure digital list-based presentation is that it is most often based on a real-world analogy, like pieces of paper laid out on a table, or cards on a cork-board. Real-world analogies, also called skeuomorphism, allow the user to carry over their experiences from interactions with a real-world system to a digital system.

Visualizations are not only characterized by their look and view transformations, but also by the implicit ordering they impose of the objects they present. List-based presentations have a very strong implicit order which therefore receives a lot of attention and care by their developers. Often users are able to change a list's ordering or ordering attributes, or even form groups of items. In two-dimensional visualizations, there are a number of possible orderings which are helpful to the user. Common ordering metrics with a low computational overhead are: by genre or artist, by music release date, or by title name. There are many possibilities of ordering by features which are not present in common audio metadata - some that come to mind are music mood, rhythm, speed, or similarity to each other. The latter is especially interesting because similarity data is increasingly being made available by large-scale online services like Echonest and Last.fm. Therefore, no data would have to be derived from the displayed music collection, but it could be retrieved from such services, for each artist to all other artists (album-to-album similarities were not available at the time the prototype for this thesis was implemented). The similarity from one artist to the other could then be illustrated by their spatial distance in 2D space. This visualization model would obviously create clusters of artists which are similar to each other, like genres, but more meaningful. 

This master's thesis will revolve around the creation of a mobile Android prototype (called "'Andromeda"') for such a 2D visualization with artist-similarity ordering, and find out whether it is a successful model in terms of visual model formation and other usability criteria. The outcome of the findings will give a hint on whether the employed method of determining and displaying artist similarity in the context of 2D visualization is promising and worthwhile to pursue further.